<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://Littlecowherd.github.io</id>
    <title>有间小酒馆</title>
    <updated>2020-01-07T03:42:26.412Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://Littlecowherd.github.io"/>
    <link rel="self" href="https://Littlecowherd.github.io/atom.xml"/>
    <subtitle>从前有个人的小酒馆</subtitle>
    <logo>https://Littlecowherd.github.io/images/avatar.png</logo>
    <icon>https://Littlecowherd.github.io/favicon.ico</icon>
    <rights>All rights reserved 2020, 有间小酒馆</rights>
    <entry>
        <title type="html"><![CDATA[Supervisor 简单使用]]></title>
        <id>https://Littlecowherd.github.io/post/03ovubxPi</id>
        <link href="https://Littlecowherd.github.io/post/03ovubxPi">
        </link>
        <updated>2019-09-29T08:55:05.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1-简介">1. 简介</h2>
<blockquote>
<p>Supervisor is a client/server system that allows its users to monitor and control a number of processes on UNIX-like operating systems.</p>
</blockquote>
<p>Supervisor是一个客户端/服务器系统，能够帮助用户监控和管理运行在类 UNIX 系统上的进程。</p>
<h2 id="2-安装">2. 安装</h2>
<p><strong>两种安装方式</strong></p>
<ol>
<li>
<p>通过 pip 安装（推荐）</p>
<pre><code class="language-bash">pip install supervisor
</code></pre>
</li>
<li>
<p>通过发行包直接安装</p>
<pre><code class="language-bash"># ubuntu Debian
apt install supervisor
# Centos Redhat 
yum install supervisor
</code></pre>
</li>
</ol>
<h2 id="3-使用">3. 使用</h2>
<ol>
<li>
<p>生成默认配置</p>
<pre><code class="language-bash">echo_supervisord_conf &gt; /etc/supervisord.conf
</code></pre>
</li>
<li>
<p>修改默认配置</p>
<pre><code class="language-bash">vim /etc/supervisord.conf
</code></pre>
<p><strong>跳到最后，修改以下几行：</strong>（千万不要忽视了<code>[include]</code>前面的分号！）</p>
<pre><code class="language-ini">;[include]
;files = /etc/supervisor/*.ini
</code></pre>
<p>去掉开头的 “ ; ”，使这两行生效。（<strong>一定注意，这两行都要取消注释！</strong>）</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/Littlecowherd/Images/master/markdown20190929163952.png" alt="" loading="lazy"></figure>
<p>这两行的作用就是，将<code>/etc/supervisor/</code>目录下所有的<code>.ini</code>文件都包含到这个配置文件里来。</p>
</li>
<li>
<p>编写自己的配置</p>
<p>进入<code>/etc/supervisor/</code>目录，编写自己的配置文件</p>
<pre><code>vim myCelery.ini
</code></pre>
<p>配置文件内容实例（如需了解配置文件的含义，请查看官方文档）</p>
<pre><code class="language-ini">[program:mp_celery]  # 这个是进程的名字，随意起
command=/root/test/venv/bin/celery -B -A Platform worker -l info  # 要运行的命令
directory=/root/mpform/Platform  # 运行命令的目录

numprocs=1
# 设置log的路径
stdout_logfile=/var/log/supervisor/mp_celery.log
stderr_logfile=/var/log/supervisor/mp_celery_error.log
autostart=true
autorestart=true
startsecs=10
stopwaitsecs = 10
priority=15
</code></pre>
</li>
<li>
<p>启动 Supervisor</p>
<pre><code class="language-bash"># supervisord -c /path/to/config
supervisord -c /etc/supervisord.conf
</code></pre>
</li>
<li>
<p>查看执行状态</p>
<pre><code>supervisorctl
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/Littlecowherd/Images/master/markdown20190929164908.png" alt="" loading="lazy"></figure>
<p>如果输出结果如上图，就说明成功了。</p>
<p>如果不是这样的，可以去<code>/var/log/supervisor</code>目录下查看日志，是不是有什么错误。</p>
<p>常用命令</p>
<pre><code class="language-bash">status       # 查看状态
reread       # 读取配置信息
update       # 加载最新的进程
stop         # 停止进程
start        # 启动进程
reload       # 重新加载配置
</code></pre>
</li>
</ol>
<h2 id="参考链接">参考链接</h2>
<ol>
<li><a href="http://supervisord.org/">Supervisor 官方文档</a></li>
<li><a href="https://www.jianshu.com/p/222d85c3833e">使用supervisor后台运行celery</a></li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ 关于Requests代理，你必须知道的]]></title>
        <id>https://Littlecowherd.github.io/post/JdmtOALbL</id>
        <link href="https://Littlecowherd.github.io/post/JdmtOALbL">
        </link>
        <updated>2019-08-21T02:55:55.000Z</updated>
        <content type="html"><![CDATA[<p>说到代理，写过爬虫的小伙伴一定都不陌生。但是<strong>你的代理真的生效了么</strong>？</p>
<p>代理主要分为以下几类：</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/Littlecowherd/Images/master/markdown20190819105520.png" alt="代理分类" loading="lazy"></figure>
<p>如果是爬虫的话，最常见的选择是高匿代理。</p>
<p>Requests 设置代理非常方便，只需传递一个 proxies 参数即可。如官方示例：</p>
<pre><code class="language-Python">import requests

proxies = {
  'http': 'http://10.10.1.10:3128',
  'https': 'http://10.10.1.10:1080',
}

requests.get('http://example.org', proxies=proxies)
</code></pre>
<p>留意一个地方，proxies 字典中有两个 key ：https 和 http，为什么要写两个 key，如果只有一个可以么？</p>
<h2 id="试试就知道了">试试就知道了</h2>
<h3 id="准备验证函数">准备验证函数</h3>
<p>这个函数会使用代理去访问两个 IP 验证网站，一个是 https，一个是 http。</p>
<pre><code class="language-Python">import requests
from bs4 import BeautifulSoup


def validate(proxies):
    https_url = 'https://ip.cn'
    http_url = 'http://ip111.cn/'
    headers = {'User-Agent': 'curl/7.29.0'}
    https_r = requests.get(https_url, headers=headers, proxies=proxies, timeout=10)
    http_r = requests.get(http_url, headers=headers, proxies=proxies, timeout=10)
    soup = BeautifulSoup(http_r.content, 'html.parser')
    result = soup.find(class_='card-body').get_text().strip().split('''\n''')[0]

    print(f&quot;当前使用代理：{proxies.values()}&quot;)
    print(f&quot;访问https网站使用代理：{https_r.json()}&quot;)
    print(f&quot;访问http网站使用代理：{result}&quot;)
</code></pre>
<h3 id="测试">测试</h3>
<ul>
<li>
<p>Case 1</p>
<pre><code class="language-Python">proxies = {
    'http': '222.189.244.56:48304',
    'https': '222.189.244.56:48304'
}
validate(proxies)
</code></pre>
<p>输出</p>
<pre><code>当前使用代理：dict_values(['222.189.244.56:48304', '222.189.244.56:48304'])
访问https网站使用代理：{'ip': '222.189.244.56', 'country': '江苏省扬州市', 'city': '电信'}
访问http网站使用代理：222.189.244.56 China / Nanjing
</code></pre>
<p>结果： <em>访问两个网站均使用了代理</em></p>
</li>
<li>
<p>Case 2</p>
<pre><code class="language-python">proxies = {
    'http': '222.189.244.56:48304'
}
validate(proxies)
</code></pre>
<p>输出</p>
<pre><code>当前使用代理：dict_values(['222.189.244.56:48304'])
访问https网站使用代理：{'ip': '118.24.234.46', 'country': '重庆市', 'city': '腾讯'}
访问http网站使用代理：222.189.244.56 China / Nanjing
</code></pre>
<p>结果： <em>只有http请求使用了代理</em></p>
</li>
<li>
<p>Case 3</p>
<pre><code class="language-python">proxies = {
    'https': '222.189.244.56:48304'
}
validate(proxies)
</code></pre>
<p>输出</p>
<pre><code>当前使用代理：dict_values(['222.189.244.56:48304'])
访问https网站使用代理：{'ip': '222.189.244.56', 'country': '江苏省扬州市', 'city': '电信'}
访问http网站使用代理：118.24.234.46 China / Nanning
</code></pre>
<p>结果： <em>只有https请求使用了代理</em></p>
</li>
</ul>
<h3 id="其他测试">其他测试</h3>
<p>通过 wireshark 抓包发现，当协议不匹配时，根本不会向代理服务器发起请求。</p>
<p>通过 postman 测试，结果与 Requests 一致，协议不同的情况下，不会走代理。</p>
<p><s>猜测可能是一种约定或者规则，类似 PAC ？（如果你知道答案，请告诉我）</s></p>
<h2 id="寻找答案">寻找答案</h2>
<p>从源码入手试试？在<code>requests.ultis</code> 中找到了这个函数：</p>
<pre><code class="language-Python">def select_proxy(url, proxies):
    &quot;&quot;&quot;Select a proxy for the url, if applicable.

    :param url: The url being for the request
    :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs
    &quot;&quot;&quot;
    proxies = proxies or {}
    urlparts = urlparse(url)
    if urlparts.hostname is None:
        return proxies.get(urlparts.scheme, proxies.get('all'))

    proxy_keys = [
        urlparts.scheme + '://' + urlparts.hostname,
        urlparts.scheme,
        'all://' + urlparts.hostname,
        'all',
    ]
    proxy = None
    for proxy_key in proxy_keys:
        if proxy_key in proxies:
            proxy = proxies[proxy_key]
            break

    return proxy
</code></pre>
<p>答案揭晓了，<strong>Requests 会根据目标 url 的协议按照一定顺序来为它选择代理。</strong> 就拿上面的 Case 2 来说：</p>
<pre><code class="language-Python">proxies = {
    'http': '222.189.244.56:48304'
}
</code></pre>
<p>请求<code>http://ip111.cn/</code>时，按照以下顺序在 proxies 字典中为这个链接选用代理：</p>
<ol>
<li>协议+域名 ：<code>http://222.189.244.56</code></li>
<li>协议：<code>http</code></li>
<li>all + 域名：<code>all://222.189.244.56</code></li>
<li>all：<code>all</code></li>
</ol>
<p>在第 2 步匹配到<code>222.189.244.56:48304</code>，然后就使用这个代理去访问目标地址。</p>
<p>而在请求<code>https://ip.cn</code>时，按照上面顺序匹配不到任何内容，就使用本地的 ip 去访问目标地址了。</p>
<p>这样也就能说明上面 3 个例子了。</p>
<h2 id="扩展">扩展</h2>
<p>官方示例中的代理包含协议，而我们测试的例子中没有但同样能够成功访问。这又是为什么呢？</p>
<pre><code class="language-Python"># 官方的
proxies = {
  'http': 'http://10.10.1.10:3128',
  'https': 'http://10.10.1.10:1080',
}
# 我们的
proxies = {
    'http': '222.189.244.56:48304',
    'https': '222.189.244.56:48304'
}
</code></pre>
<p>答案同样可以在源码里找到，请看下面这两个函数：</p>
<p><code>requests.apdpters</code></p>
<pre><code class="language-Python">def get_connection(self, url, proxies=None):
    &quot;&quot;&quot;Returns a urllib3 connection for the given URL. This should not be
    called from user code, and is only exposed for use when subclassing the
    :class:`HTTPAdapter &lt;requests.adapters.HTTPAdapter&gt;`.

    :param url: The URL to connect to.
    :param proxies: (optional) A Requests-style dictionary of proxies used on this request.
    :rtype: urllib3.ConnectionPool
    &quot;&quot;&quot;
    proxy = select_proxy(url, proxies)

    if proxy:
        proxy = prepend_scheme_if_needed(proxy, 'http')
        proxy_url = parse_url(proxy)
        if not proxy_url.host:
            raise InvalidProxyURL(&quot;Please check proxy URL. It is malformed&quot;
                                    &quot; and could be missing the host.&quot;)
        proxy_manager = self.proxy_manager_for(proxy)
        conn = proxy_manager.connection_from_url(url)
    else:
        # Only scheme should be lower case
        parsed = urlparse(url)
        url = parsed.geturl()
        conn = self.poolmanager.connection_from_url(url)

    return conn
</code></pre>
<p>看这一行代码：<code>proxy = prepend_scheme_if_needed(proxy, 'http')</code>，找到这个函数的定义:</p>
<pre><code class="language-python">def prepend_scheme_if_needed(url, new_scheme):
    &quot;&quot;&quot;Given a URL that may or may not have a scheme, prepend the given scheme.
    Does not replace a present scheme with the one provided as an argument.

    :rtype: str
    &quot;&quot;&quot;
    scheme, netloc, path, params, query, fragment = urlparse(url, new_scheme)

    # urlparse is a finicky beast, and sometimes decides that there isn't a
    # netloc present. Assume that it's being over-cautious, and switch netloc
    # and path if urlparse decided there was no netloc.
    if not netloc:
        netloc, path = path, netloc

    return urlunparse((scheme, netloc, path, params, query, fragment))
</code></pre>
<p>从注释中可以找到答案：</p>
<p><strong>如果代理提供了协议，不做改变；如果代理没有协议的话，就为代理加上<code>http</code>协议。</strong></p>
<h2 id="结论">结论</h2>
<ol>
<li>Requests 会按照目标url的协议来为它配置代理。基于此你可以为不同的协议甚至不同域名设置不同的代理，如果想为所有请求使用同一个代理，那直接使用 all 作为 key 来设置即可。</li>
<li>代理地址如果没有指明协议，则默认使用 http 请求。</li>
</ol>
<h2 id="参考链接">参考链接</h2>
<ul>
<li><a href="https://imququ.com/post/web-proxy.html">HTTP 代理原理及实现（一）</a></li>
<li><a href="https://imququ.com/post/web-proxy-2.html">HTTP 代理原理及实现（二）</a></li>
<li><a href="https://blog.51cto.com/14062184/2315723">什么是透明、匿名、高匿代理？详解！</a></li>
<li><a href="https://www.hitoy.org/difference-between-http-and-https-proxy.html">HTTP代理和HTTPS代理的区别</a></li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[删除Git仓库的所有历史提交记录]]></title>
        <id>https://Littlecowherd.github.io/post/ko1lNI3Ex</id>
        <link href="https://Littlecowherd.github.io/post/ko1lNI3Ex">
        </link>
        <updated>2019-08-08T10:53:23.000Z</updated>
        <content type="html"><![CDATA[<p>在开发项目过程中，很可能在提交 git  时泄露了一些敏感信息，本地尚且无妨。倘若要同步到 GitHub 等公开平台，那就一定要消除这些信息。</p>
<p><strong>操作方式如下：</strong></p>
<blockquote>
<p>Deleting the <code>.git</code> folder may cause problems in your git repository. If you want to delete all your commit history but keep the code in its current state, it is very safe to do it as in the following:</p>
<p>删除 .git 文件夹可能会导致 git 存储库出现问题。如果要删除所有提交历史记录但保持代码处于当前状态，则执行此操作非常安全，如下所示：</p>
<ol>
<li>
<p>Checkout</p>
<p><code>git checkout --orphan latest_branch</code></p>
</li>
<li>
<p>Add all the files</p>
<p><code>git add -A</code></p>
</li>
<li>
<p>Commit the changes</p>
<p><code>git commit -am &quot;commit message&quot;</code></p>
</li>
<li>
<p>Delete the branch</p>
<p><code>git branch -D master</code></p>
</li>
<li>
<p>Rename the current branch to master</p>
<p><code>git branch -m master</code></p>
</li>
<li>
<p>Finally, force update your repository</p>
<p><code>git push -f origin master</code></p>
</li>
</ol>
<p>PS: this will not keep your old commit history around</p>
</blockquote>
<p>这组命令对于发布开源分支来说很有帮助，新的分支含有之前的全部代码但不包含之前的提交记录，就算你不小心把敏感信息提交到了 GitHub，也可以用它来亡羊补牢。</p>
<p><strong>命令说明</strong></p>
<blockquote>
<p><code>git checkout --orphan &lt;new_branch&gt;</code></p>
<p>Create a new <em>orphan</em> branch, named &lt;new_branch&gt;, started from &lt;start_point&gt; and switch to it. The first commit made on this new branch will have no parents and it will be the root of a new history totally disconnected from all the other branches and commits.</p>
<p>创建一个名为 &lt;new_branch&gt; 的新<em>孤立</em>分支，从 &lt;start_point&gt; 启动并切换到该分支。在这个新分支上进行的第一次提交将没有父项，它将成为与所有其他分支和提交完全断开的新历史的根。</p>
</blockquote>
<p>大致意思就是：创建一个名为  &lt;new_branch&gt;  的 全新的<em>孤立</em>分支，可以当成一个全新的根节点。</p>
<p><strong>参考链接</strong></p>
<ol>
<li>
<p><a href="https://stackoverflow.com/questions/13716658/how-to-delete-all-commit-history-in-github">how to delete all commit history in github? </a></p>
</li>
<li>
<p><a href="https://www.jianshu.com/p/cad4d2ec4da5">Git checkout 用法总结</a></p>
</li>
<li>
<p><a href="https://git-scm.com/docs/git-checkout#Documentation/git-checkout.txt---orphanltnewbranchgt">checkout - Git 官方文档</a></p>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ py-spy常见问题及使用说明]]></title>
        <id>https://Littlecowherd.github.io/post/TICCX3MX-</id>
        <link href="https://Littlecowherd.github.io/post/TICCX3MX-">
        </link>
        <updated>2019-08-01T10:35:09.000Z</updated>
        <content type="html"><![CDATA[<h2 id="常见问题">常见问题</h2>
<h3 id="failed-to-suspend-process">Failed to suspend process</h3>
<p>上篇文章说到了通过 py-spy 来分析Python进程，进而找到程序中的问题。有小伙伴在使用的时候遇到了这样的错误：</p>
<pre><code class="language-bash">[test@localhost]# py-spy --pid 15235
Error: Failed to suspend process
Reason: EPERM: Operation not permitted
</code></pre>
<p>先看下报错信息：暂停进程失败，原因是操作不允许。</p>
<p>百度\Google 一下，相关结果只有两条，并不能解决问题。</p>
<figure data-type="image" tabindex="1"><img src="https://Littlecowherd.github.io/post-images/1564652166145.png" alt="" loading="lazy"></figure>
<p>这个时候别慌，去看<a href="https://github.com/benfred/py-spy">官方文档</a>，虽然是英文写的，但是读起来并不会特别困难，实在不行就用翻译插件。</p>
<p>果然找到了一条相关的，在命令中加入 <code>--nonblocking</code>参数就可以避免暂停 Python 进程。</p>
<blockquote>
<h3 id="how-can-you-avoid-pausing-the-python-program">How can you avoid pausing the Python program?</h3>
<p>By setting the <code>--nonblocking</code> option, py-spy won't pause the target python you are profiling from. While the performance impact of sampling from a process with py-spy is usually extremely low, setting this option will totally avoid interrupting your running python program.</p>
</blockquote>
<p>尝试一下，果然可以了。</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/Littlecowherd/Images/master/markdown20190731104040.png" alt="" loading="lazy"></figure>
<p>官方文档中还有在 Docker、Kubernetes 环境下运行的特殊说明、OS X 环境下的特殊问题等，可能暂时用不到，但是一定要了解。等到用的时候知道有这么回事，知道去哪里找解决方法。</p>
<p><mark>我只是把我遇到的问题写了出来，如果你遇到了其他问题，强烈建议你去读一下官方文档。</mark></p>
<h2 id="常用命令">常用命令</h2>
<p><strong>监控 Python 进程</strong></p>
<pre><code class="language-bash">py-spy --pid 12345
# OR
py-spy -- python myprogram.py
</code></pre>
<p><em>注意，如果直接通过 pid 参数来运行 py-spy 需要用到 root 权限。第二种启动方法会将 Python 进程以 py-spy子进程的形式启动，故而不需要 root 权限</em></p>
<p><strong>绘制火焰图</strong></p>
<pre><code class="language-bash">py-spy --flame profile.svg --pid 12345
# OR
py-spy --flame profile.svg -- python myprogram.py
</code></pre>
<p><em>注意，图片的类型一定得是 svg</em></p>
<h2 id="小结">小结</h2>
<p>遇到问题，可能很多人的第一反应都是去求助搜索引擎，这种方法对应某些情况来说的确很好用（比如说，这个工具用的人很多，有很多人都遇到过类似的问题）。但像这次，相关的结果很少，那一定要去看看官方文档，如果官方文档任然不能解决你的问题，还可以去提 issue（一定要把问题说清楚，啥环境、什么问题，以及你的目的等等）。阅读源码当然也是一个途径。</p>
<p>官方文档，永远是帮我们了解某个工具的最好途径之一，甚至可以去掉之一。</p>
<h2 id="参考信息">参考信息</h2>
<ol>
<li><a href="https://github.com/benfred/py-spy">py-spy 官方文档</a></li>
<li><a href="https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way/blob/master/README-zh_CN.md">提问的智慧</a></li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ 记一次Scrapy进程卡死的Debug过程]]></title>
        <id>https://Littlecowherd.github.io/post/ji-yi-ci-scrapy-jin-cheng-qia-si-de-debug-guo-cheng</id>
        <link href="https://Littlecowherd.github.io/post/ji-yi-ci-scrapy-jin-cheng-qia-si-de-debug-guo-cheng">
        </link>
        <updated>2019-07-30T06:41:09.000Z</updated>
        <content type="html"><![CDATA[<h2 id="发现问题">发现问题</h2>
<p>日常巡查数据入库情况时，发现最新数据的入库时间停在了凌晨。立刻登录远程服务器，尝试定位问题。</p>
<ol>
<li>
<p>定时任务是否正常工作，是否有报错信息</p>
<pre><code>crontab -l
</code></pre>
<p>经检查发现，定时任务工作正常，也没有运行报错的记录。</p>
</li>
<li>
<p>查看系统进程，采集程序是否运行</p>
<pre><code>ps -ef | grep xxxappspider
</code></pre>
<p>输出信息如下</p>
<figure data-type="image" tabindex="1"><img src="https://Littlecowherd.github.io/post-images/1564469201050.png" alt="" loading="lazy"></figure>
<p>可以看到进程在凌晨 01:40 成功启动了，但是一直没有执行完成，推测是代码出现了死锁等问题？查看日志也没有记录到有用的信息。</p>
</li>
<li>
<p>检查代码，尝试复现该bug</p>
<p>在服务器手动执行程序，均能正常运行。简单复查代码，也没有发现哪里会导致死锁。</p>
</li>
</ol>
<h2 id="解决问题">解决问题</h2>
<p>由于手头还有比较急的任务，只是给程序加上了更详细的日志记录，然后 kill 掉卡住的进程，让定时任务重新运行起来。</p>
<p>第二天问题再次出现，同样是凌晨的定时任务出现了卡死的情况。首先排除服务器原因，相同服务器其他任务均正常运行。其次排除存储原因，我们的采集结果是统一入到 Kafka 队列，经过一系列的操作后存储到数据库的。这个 Kafka 队列所有应用都在使用，如果出现问题不会只这一个任务。然后大致可以确定，是这个任务在<strong>凌晨</strong>运行时，会因为某些原因导致卡死。</p>
<p>好了，是时候祭出我们的大杀器： <a href="https://github.com/benfred/py-spy">py-spy</a></p>
<p>这是一个 Python 的性能分析工具，我是在听<a href="https://pythonhunter.org/">《捕蛇者说》</a>的时候了解到的这个库，现在正好拿来用用。</p>
<p>先简单看下怎么用：</p>
<pre><code class="language-bash">[test@localhost ~]# py-spy --help
py-spy 0.1.11
A sampling profiler for Python programs

USAGE:
    py-spy [FLAGS] [OPTIONS] --pid &lt;pid&gt; [python_program]...

FLAGS:
        --dump           Dump the current stack traces to stdout
    -F, --function       Aggregate samples by function name instead of by line number
    -h, --help           Prints help information
        --nonblocking    Don't pause the python process when collecting samples. Setting this option will reduce the
                         perfomance impact of sampling, but may lead to inaccurate results
    -V, --version        Prints version information

OPTIONS:
    -d, --duration &lt;duration&gt;    The number of seconds to sample for when generating a flame graph [default: 2]
    -f, --flame &lt;flamefile&gt;      Generate a flame graph and write to a file
    -p, --pid &lt;pid&gt;              PID of a running python program to spy on
    -r, --rate &lt;rate&gt;            The number of samples to collect per second [default: 100]

ARGS:
    &lt;python_program&gt;...    commandline of a python program to run

</code></pre>
<p>只需要输入 Python 进程的 pid 就能直观的显示该进程中各项任务的耗时情况。更重要的是，它<strong>不需要重启代码</strong>就能运行，非常适合我们现在遇到的情况。</p>
<p>安装很简单：</p>
<pre><code class="language-bash">pip install py-spy
</code></pre>
<p>使用很简单：</p>
<pre><code class="language-bash"># 先找到这个卡住的Python进程的pid
ps -ef |grep python |grep ***
# 启动 py-spy 观察这进程
py-spy --pid 32179
</code></pre>
<p>输出信息如下：</p>
<figure data-type="image" tabindex="2"><img src="https://Littlecowherd.github.io/post-images/1564469215602.png" alt="" loading="lazy"></figure>
<p>可以看到，程序是卡在了建立网络连接的部分。<code>hand_request</code>是一个为某个App请求签名的函数，被单独放在了<code>utils</code>这个目录下。接下来就简单了，找到这个函数，在第43行，发现了一个 post 请求。嗯，其实不管是 post 还是 get 都不要紧，重要的是这个请求没有加 <code>timeout</code> 参数！！！</p>
<p><strong>Requests 文档里写的很清楚了，如果没有超时参数，程序有可能永远失去响应。</strong></p>
<blockquote>
<h2 id="超时">超时</h2>
<p>你可以告诉 requests 在经过以 <code>timeout</code> 参数设定的秒数时间之后停止等待响应。基本上所有的生产代码都应该使用这一参数。如果不使用，你的程序可能会永远失去响应：</p>
<pre><code>&gt;&gt;&gt; requests.get('http://github.com', timeout=0.001)
Traceback (most recent call last):
  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;
requests.exceptions.Timeout: HTTPConnectionPool(host='github.com', port=80): Request timed out. (timeout=0.001)
</code></pre>
<p>注意</p>
<p><code>timeout</code> 仅对连接过程有效，与响应体的下载无关。 <code>timeout</code> 并不是整个下载响应的时间限制，而是如果服务器在 <code>timeout</code> 秒内没有应答，将会引发一个异常（更精确地说，是在<code>timeout</code> 秒内没有从基础套接字上接收到任何字节的数据时）If no timeout is specified explicitly, requests do not time out.</p>
</blockquote>
<p>至此，Debug完成。</p>
<h2 id="总结">总结</h2>
<p>这么低级的 bug，确实是我自己写的。</p>
<p>当初写的时候忽视了这个问题，测试的时候没有发现问题也就过去了。第一次发现问题的时候，查问题并不仔细，只简单看了<code>spiders</code>目录下的几个爬虫代码，没有去检查<code>utils</code>目录下的工具类的代码，故而并没有找到具体问题。第二次通过 py-spy 的帮助，成功找到并解决了问题。</p>
<p>解决问题后，反思下原因：很可能是这个 App 会在凌晨进行维护，导致请求没有得到响应，同时没有设置超时函数，程序就会一直卡在哪里。</p>
<p>最后，推荐一下《捕蛇者说》，这是一个关于“编程、程序员、Python”的中文博客。没事听听大佬们唠嗑，真的很涨知识。</p>
<h2 id="参考链接">参考链接</h2>
<ol>
<li><a href="https://github.com/benfred/py-spy">py-spy 的官方地址</a></li>
<li><a href="https://pythonhunter.org/episodes/2">Ep 02. 开发中的碎碎念 ——《捕蛇者说》</a></li>
<li><a href="https://2.python-requests.org//zh_CN/latest/user/quickstart.html#id10">超时 ——Requests 官方文档</a></li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[超详细CloudCone使用指南]]></title>
        <id>https://Littlecowherd.github.io/post/chao-xiang-xi-cloudcone-shi-yong-zhi-nan</id>
        <link href="https://Littlecowherd.github.io/post/chao-xiang-xi-cloudcone-shi-yong-zhi-nan">
        </link>
        <updated>2019-04-18T09:26:51.000Z</updated>
        <content type="html"><![CDATA[<h2 id="起因">起因</h2>
<p>相较于其他 VPS 提供商（ <a href="https://www.vultr.com/?ref=7468133">Vultr</a> 、<a href="https://m.do.co/c/b4f1eed9d029">DigitalOcean</a>、<a href="https://www.linode.com/">Linode</a> 等等），CloudCone 比较新，知名度比较低。得益于这一点，这家服务商的 IP 段在学校还能正常访问，这也是我选择它的最根本原因。</p>
<h2 id="开始试用">开始试用</h2>
<h3 id="1-注册账号">1. 注册账号</h3>
<p>你可以点击 <a href="https://app.cloudcone.com/?ref=486">CloudCone</a> 来登录或者注册，如下图所示。</p>
<figure data-type="image" tabindex="1"><img src="https://raw.githubusercontent.com/Littlecowherd/Images/master/markdown/20181220133730.png" alt="" loading="lazy"></figure>
<p>如果已有账号 ，输入账号密码点击 Log in 即可登录。如果没有账号请点击 Sign up 跳转到注册界面，如下图所示。</p>
<figure data-type="image" tabindex="2"><img src="https://raw.githubusercontent.com/Littlecowherd/Images/master/markdown/20181220134049.png" alt="" loading="lazy"></figure>
<p>按照图中标识填写注册完成，点击 Create My Account 即可创建账号。</p>
<p><em>注：How did you hear about us？ 这个问题可以不填写。</em></p>
<h3 id="2-充值">2. 充值</h3>
<p>注册成功，登录账号会看到如下一个界面。</p>
<figure data-type="image" tabindex="3"><img src="https://raw.githubusercontent.com/Littlecowherd/Images/master/markdown/20181220194449.png" alt="" loading="lazy"></figure>
<p>因为我已经有一台云服务器了，你看到的界面可能和我的有些不一样，但是没啥关系。</p>
<p>点击右上角的加号，选择 billing，进入充值页面，如下图所示。</p>
<figure data-type="image" tabindex="4"><img src="https://raw.githubusercontent.com/Littlecowherd/Images/master/markdown/20181220194745.png" alt="" loading="lazy"></figure>
<p>进入充值页面后选择 Add funds</p>
<figure data-type="image" tabindex="5"><img src="https://raw.githubusercontent.com/Littlecowherd/Images/master/markdown/20181220194958.png" alt="" loading="lazy"></figure>
<p>可以看到支持的充值方式为有 PayPal 和 Alipay（支付宝）等方式</p>
<figure data-type="image" tabindex="6"><img src="https://raw.githubusercontent.com/Littlecowherd/Images/master/markdown/20181220195104.png" alt="" loading="lazy"></figure>
<p>说一下这两种支付方式的区别：PayPal 可以自定义充值金额，最低充值金额是 $1，但是不够方便，可能还得注册账号绑定银行卡；支付宝要方便的多，但是最低充值金额是 $5，30 多块人民币。具体怎么选看你的喜好。</p>
<p>值得一提的是，这个页面的最下面有个 Promotional Codes，如果有优惠码的话，可以填写在这里，如下图所示。</p>
<figure data-type="image" tabindex="7"><img src="https://raw.githubusercontent.com/Littlecowherd/Images/master/markdown/20181220204412.png" alt="" loading="lazy"></figure>
<p>关于这个优惠码，我问了客服，优惠码没拿到，他倒是给了我一个促销链接。请点击<a href="https://cloudcone.com/offers">这里</a>查看 。此外这家服务商偶尔还会发送一些促销邮件，有一些价格很低的套餐值得一试。</p>
<h3 id="3-选购服务器">3. 选购服务器</h3>
<p>再次点击右上角的加号，选择 Cloud Server ，进入配置选择界面，如下图。</p>
<figure data-type="image" tabindex="8"><img src="https://raw.githubusercontent.com/Littlecowherd/Images/master/markdown/20181220222241.png" alt="" loading="lazy"></figure>
<p>新用户有首月 $1.99 的优惠，我这里已经变回正常价格了。</p>
<p>可供选择的镜像类型如下图</p>
<figure data-type="image" tabindex="9"><img src="https://raw.githubusercontent.com/Littlecowherd/Images/master/markdown/20181220222459.png" alt="" loading="lazy"></figure>
<p><em>这里说明一点， 列表最下放的 CentOS 7.5 是开启了BBR加速的，访问速度可能会好一点。当然，也可以选择默认不开启BBR的服务器，然后自己手动启动BBR加速，也不会很麻烦。</em></p>
<p>根据自己的需要选择配置，如果只是用来搭梯子的话，统统选择最低配置就完全够用了。 再有一点，hostname项，如果有自己的域名的话可以填写，也可以随便起个名字（Test、Tom、Jerry……）。选择完之后，点击 Deploy Server 生成服务器。</p>
<h3 id="4-查看服务器">4. 查看服务器</h3>
<p>点击最上方导航栏的 Cumpute，就可以看到你刚刚选购完的服务器了，点击 Manage 进入管理页面。</p>
<figure data-type="image" tabindex="10"><img src="https://raw.githubusercontent.com/Littlecowherd/Images/master/markdown/cc20190311173956.png" alt="" loading="lazy"></figure>
<p>通过管理界面，你可以查看 VPS 实例的资源使用情况，或者进行开关机、重启、连接终端、更换操作系统、销毁vps等一系列操作。</p>
<figure data-type="image" tabindex="11"><img src="https://raw.githubusercontent.com/Littlecowherd/Images/master/markdown/cc20190311170422.png" alt="实例详细信息" loading="lazy"></figure>
<p>如果你想看更详细的资源使用信息（CPU 利用率、内存用量、网速、硬盘用量、平均负载），需要点击上图中的红框，获取安装 stats colelctor 插件的命令，完成安装后即可查看详细资源信息。</p>
<p><em>P.S.  3 TB = 3072 GB，我从来没用完过……</em></p>
<h3 id="5-连接并管理服务器">5. 连接并管理服务器</h3>
<p>推荐使用 Xshell、Mobaxterm、Putty 等 SSH 工具管理你的 VPS。</p>
<p>在你完成购买后，CloudCone 会将该实例的 IP 地址、用户名和密码发送到你的注册邮箱，如果你没收到的话，注意查看下垃圾箱。实在不行的话，可以通过 Access → Reset root password 重新获取，如下图。</p>
<figure data-type="image" tabindex="12"><img src="https://raw.githubusercontent.com/Littlecowherd/Images/master/markdown/cc20190311171918.png" alt="重置密码" loading="lazy"></figure>
<p>使用 SSH 连接到服务器，然后部署小飞机之类的，基本配置并不复杂，这里就不展开讲了。（具体步骤可以去看小飞机的文档：<a href="https://github.com/shadowsocks/shadowsocks/wiki/Shadowsocks-%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E">地址</a>）</p>
<h3 id="6-科学上网测试">6. 科学上网测试</h3>
<p>测试环境：200M带宽<br>
效果如下图，有兴趣的朋友可以上手试试。</p>
<figure data-type="image" tabindex="13"><img src="https://raw.githubusercontent.com/Littlecowherd/Images/master/markdown/cc20190311172855.png" alt="Youtobe" loading="lazy"></figure>
]]></content>
    </entry>
</feed>